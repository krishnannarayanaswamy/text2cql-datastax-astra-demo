{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/krishnannarayanaswamy/text2cql-datastax-astra-demo/blob/main/Text2CQL_DataStax_Astra.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b69b5b27-f4dc-439b-8ae5-b3f776fa3745",
      "metadata": {
        "id": "b69b5b27-f4dc-439b-8ae5-b3f776fa3745"
      },
      "source": [
        "# Using LLMs to Generate CQL"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "107770b0-abda-43ee-af5d-eae2100b65ad",
      "metadata": {
        "id": "107770b0-abda-43ee-af5d-eae2100b65ad"
      },
      "source": [
        "Since LLMs seem to excel at a lot of things, we wanted to show how they can be used to generate CQL to query your Cassandra tables. This notebook provides a guide derived from the [SQL-PaLM](https://arxiv.org/abs/2306.00739) paper on how to automatically show the LLM your DB schema, and let it inform the LLM on querying your data."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1ffeccb0-d70c-4f15-b924-6e8cd7a5b30e",
      "metadata": {
        "id": "1ffeccb0-d70c-4f15-b924-6e8cd7a5b30e"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b71640c3-3495-4459-837e-08d6e80ed410",
      "metadata": {
        "id": "b71640c3-3495-4459-837e-08d6e80ed410"
      },
      "source": [
        "#### Requirements"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "b43e0d9c-c760-485f-877b-df577f2cfacf",
      "metadata": {
        "id": "b43e0d9c-c760-485f-877b-df577f2cfacf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "762b4925-fff4-4973-8382-2107dda410be"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai\n",
            "  Downloading openai-1.13.3-py3-none-any.whl (227 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m227.4/227.4 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting cassandra-driver\n",
            "  Downloading cassandra_driver-3.29.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.8/18.8 MB\u001b[0m \u001b[31m47.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai)\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.6.3)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai) (4.10.0)\n",
            "Collecting geomet<0.3,>=0.1 (from cassandra-driver)\n",
            "  Downloading geomet-0.2.1.post1-py3-none-any.whl (18 kB)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.6)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from geomet<0.3,>=0.1->cassandra-driver) (8.1.7)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from geomet<0.3,>=0.1->cassandra-driver) (1.16.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.2.2)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
            "  Downloading httpcore-1.0.4-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.8/77.8 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.3 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.16.3)\n",
            "Installing collected packages: h11, geomet, httpcore, cassandra-driver, httpx, openai\n",
            "Successfully installed cassandra-driver-3.29.0 geomet-0.2.1.post1 h11-0.14.0 httpcore-1.0.4 httpx-0.27.0 openai-1.13.3\n"
          ]
        }
      ],
      "source": [
        "# Install requirements, if not already installed\n",
        "!pip install openai cassandra-driver"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ae7063e7-80c4-49ae-84f1-3345aa3bbef1",
      "metadata": {
        "id": "ae7063e7-80c4-49ae-84f1-3345aa3bbef1"
      },
      "source": [
        "#### Connect to Services"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "9767fc7a-a9d8-4e89-b32c-805243700348",
      "metadata": {
        "id": "9767fc7a-a9d8-4e89-b32c-805243700348",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6c017eaa-6067-410e-aa4a-46132cfcefc3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "OpenAI API Key: ··········\n"
          ]
        }
      ],
      "source": [
        "# Initialize the OpenAI Client\n",
        "import os\n",
        "\n",
        "from getpass import getpass\n",
        "import openai\n",
        "\n",
        "if \"OPENAI_API_KEY\" not in os.environ:\n",
        "    os.environ[\"OPENAI_API_KEY\"] = getpass(\"OpenAI API Key: \")\n",
        "\n",
        "client = openai.OpenAI()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "6a47bad8-9e13-41fa-af6d-724b72f702cd",
      "metadata": {
        "id": "6a47bad8-9e13-41fa-af6d-724b72f702cd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        },
        "outputId": "1f51f9d7-959c-4437-f958-b539ea672db3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Astra DB Token: ··········\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-c4c5e74d-4298-40b5-8d79-0390cf073108\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-c4c5e74d-4298-40b5-8d79-0390cf073108\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving secure-connect-multilingual.zip to secure-connect-multilingual (1).zip\n",
            "Astra DB Keyspace: fintech\n"
          ]
        }
      ],
      "source": [
        "# Connect to a Cassandra Cluster and initialize the session\n",
        "import re\n",
        "\n",
        "from cassandra.cluster import Cluster\n",
        "from cassandra.auth import PlainTextAuthProvider\n",
        "from getpass import getpass\n",
        "from google.colab import files\n",
        "\n",
        "ASTRA_TOKEN = os.environ.get(\n",
        "    \"ASTRA_DB_TOKEN\",\n",
        "    getpass(\"Astra DB Token: \")\n",
        ")\n",
        "\n",
        "ASTRA_BUNDLE_PATH = os.environ.get(\n",
        "    \"ASTRA_DB_BUNDLE_PATH\",\n",
        "    list(files.upload().keys())[0],\n",
        ")\n",
        "\n",
        "ASTRA_KEYSPACE = os.environ.get(\n",
        "    \"ASTRA_DB_KEYSPACE\",\n",
        "    input(\"Astra DB Keyspace: \"),\n",
        ")\n",
        "\n",
        "cloud_config = {\n",
        "    'secure_connect_bundle': ASTRA_BUNDLE_PATH\n",
        "}\n",
        "auth_provider = PlainTextAuthProvider(\"token\", ASTRA_TOKEN)\n",
        "\n",
        "def execute_statement(statement: str):\n",
        "    # This is a simple wrapper around executing CQL statements in our\n",
        "    # Cassandra cluster, and either raising an error or returning the results\n",
        "    try:\n",
        "        rows = session.execute(statement)\n",
        "        return rows.all()\n",
        "    except:\n",
        "        print(f\"Query Failed: {statement}\")\n",
        "        raise\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cluster = Cluster(cloud=cloud_config, auth_provider=auth_provider)\n",
        "session = cluster.connect(keyspace=ASTRA_KEYSPACE)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0f0OL9JQC1bd",
        "outputId": "c06225bf-2e6f-414c-afcd-da62e23e1866"
      },
      "id": "0f0OL9JQC1bd",
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:cassandra.cluster:Downgrading core protocol version from 66 to 65 for 49293bf1-9bb8-4c65-a060-cf566066cc00-us-east1.db.astra.datastax.com:29042:b1317c54-97aa-4844-85b6-fa62d7a344ef. To avoid this, it is best practice to explicitly set Cluster(protocol_version) to the version supported by your cluster. http://datastax.github.io/python-driver/api/cassandra/cluster.html#cassandra.cluster.Cluster.protocol_version\n",
            "WARNING:cassandra.cluster:Downgrading core protocol version from 65 to 5 for 49293bf1-9bb8-4c65-a060-cf566066cc00-us-east1.db.astra.datastax.com:29042:b1317c54-97aa-4844-85b6-fa62d7a344ef. To avoid this, it is best practice to explicitly set Cluster(protocol_version) to the version supported by your cluster. http://datastax.github.io/python-driver/api/cassandra/cluster.html#cassandra.cluster.Cluster.protocol_version\n",
            "ERROR:cassandra.connection:Closing connection <AsyncoreConnection(135265819302864) 49293bf1-9bb8-4c65-a060-cf566066cc00-us-east1.db.astra.datastax.com:29042:b1317c54-97aa-4844-85b6-fa62d7a344ef> due to protocol error: Error from server: code=000a [Protocol error] message=\"Beta version of the protocol used (5/v5-beta), but USE_BETA flag is unset\"\n",
            "WARNING:cassandra.cluster:Downgrading core protocol version from 5 to 4 for 49293bf1-9bb8-4c65-a060-cf566066cc00-us-east1.db.astra.datastax.com:29042:b1317c54-97aa-4844-85b6-fa62d7a344ef. To avoid this, it is best practice to explicitly set Cluster(protocol_version) to the version supported by your cluster. http://datastax.github.io/python-driver/api/cassandra/cluster.html#cassandra.cluster.Cluster.protocol_version\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "890b2537-f585-4f31-bb20-ed71910eb586",
      "metadata": {
        "jp-MarkdownHeadingCollapsed": true,
        "id": "890b2537-f585-4f31-bb20-ed71910eb586"
      },
      "source": [
        "#### (Optional) Dummy DB Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "db89558d-f24b-4517-bf46-97c65c2071ac",
      "metadata": {
        "id": "db89558d-f24b-4517-bf46-97c65c2071ac"
      },
      "source": [
        "Feel free to skip this section if you are instead adapting the notebook to fit your existing Cassandra Database. Here, we will utilize the python `cassandra-driver` package to connect to a DB and create some fake tables. This schema is pulled from [this DataStax example](https://www.datastax.com/learn/data-modeling-by-example/digital-library-data-model) on creating a data model for a digital music library."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "df4e69c2-0cda-42e3-8718-8f7ac6da230f",
      "metadata": {
        "id": "df4e69c2-0cda-42e3-8718-8f7ac6da230f"
      },
      "outputs": [],
      "source": [
        "# Create all necessary tables\n",
        "create_tables_cql = \"\"\"CREATE TABLE IF NOT EXISTS customerprofile (\n",
        "    client_id INT,\n",
        "    surname TEXT,\n",
        "    credit_score INT,\n",
        "    location TEXT,\n",
        "    gender TEXT,\n",
        "    age INT,\n",
        "    balance DECIMAL,\n",
        "    has_credit_card BOOLEAN,\n",
        "    estimated_salary DECIMAL,\n",
        "    satisfaction_score INT,\n",
        "    card_type TEXT,\n",
        "    point_earned INT,\n",
        "    PRIMARY KEY (client_id)\n",
        ");\"\"\"\n",
        "\n",
        "create_index_cql = \"\"\"CREATE CUSTOM INDEX IF NOT EXISTS location_idx ON customerprofile (location) USING 'org.apache.cassandra.index.sai.StorageAttachedIndex';\n",
        "\n",
        "CREATE CUSTOM INDEX IF NOT EXISTS has_credit_card_idx ON customerprofile (has_credit_card) USING 'org.apache.cassandra.index.sai.StorageAttachedIndex';\n",
        "\n",
        "CREATE CUSTOM INDEX IF NOT EXISTS credit_score_idx ON customerprofile (credit_score) USING 'org.apache.cassandra.index.sai.StorageAttachedIndex';\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# This parses the text above into executable strings by the driver\n",
        "for statement in create_tables_cql.split(\";\"):\n",
        "    if len(statement.strip()):\n",
        "        execute_statement(statement.strip())"
      ],
      "metadata": {
        "id": "mDiQMHefPziE"
      },
      "id": "mDiQMHefPziE",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "03471e5c-47f0-4abd-b742-673a2524f0e2",
      "metadata": {
        "id": "03471e5c-47f0-4abd-b742-673a2524f0e2"
      },
      "outputs": [],
      "source": [
        "# This parses the text above into executable strings by the driver\n",
        "for statement in create_index_cql.split(\";\"):\n",
        "    if len(statement.strip()):\n",
        "        execute_statement(statement.strip())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "from cassandra.query import SimpleStatement\n",
        "\n",
        "with open('clients-dataset.csv', 'r') as file:\n",
        "    reader = csv.reader(file)\n",
        "    headers = next(reader)\n",
        "    query = SimpleStatement(f\"INSERT INTO {ASTRA_KEYSPACE}.customerprofile (client_id, surname, credit_score, location, gender, age, \" \\\n",
        "            \"balance, has_credit_card, estimated_salary, satisfaction_score, card_type, point_earned\" \\\n",
        "            \") VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)\")\n",
        "\n",
        "    for row in reader:\n",
        "        # Create a dictionary for the row using headers as keys\n",
        "        row_dict = dict(zip(headers, row))\n",
        "\n",
        "        # Insert values into Astra database\n",
        "        session.execute(query, (int(row_dict['CustomerId']), row_dict['Surname'], int(row_dict['CreditScore']), row_dict['Geography'], row_dict['Gender'], int(row_dict['Age']), float(row_dict['Balance']), bool(row_dict['HasCrCard']),\n",
        "                                float(row_dict['EstimatedSalary']), int(row_dict['Satisfaction Score']), row_dict['Card Type'], int(row_dict['Point Earned'])))\n",
        "\n",
        "        print(f\"Inserted client {row_dict['CustomerId']} into Astra DB\")\n"
      ],
      "metadata": {
        "id": "D9BY6lA3FVYI"
      },
      "id": "D9BY6lA3FVYI",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "2495b975-8342-4386-b92d-5ae05b783853",
      "metadata": {
        "jp-MarkdownHeadingCollapsed": true,
        "id": "2495b975-8342-4386-b92d-5ae05b783853"
      },
      "source": [
        "## (Optional) Give the LLM Additional Context with the Built-in 'Comments' Column"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "23820cb9-d683-48bb-9440-b398446df4c9",
      "metadata": {
        "id": "23820cb9-d683-48bb-9440-b398446df4c9"
      },
      "source": [
        "LLM response quality greatly depends on the context they've been given - the more concise descriptions they have access to, the better. We can choose to augment the DB schema we pass to the model by utilizing the built-in `comment` property of CQL tables.\n",
        "\n",
        "NOTE: You can also include these comments at table creation by using the `WITH <table property 1> AND <table property 2> ... AND comment = '<comment>'` syntax"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "04d67d6c-6938-46ac-a5b5-8baaea54272a",
      "metadata": {
        "id": "04d67d6c-6938-46ac-a5b5-8baaea54272a"
      },
      "outputs": [],
      "source": [
        "add_comments_cql = f\"\"\"\n",
        "ALTER TABLE customerprofile WITH comment = 'Customers profile with their credit scores and balance';\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "db29bea2-7600-495b-b57b-e2937fb0753f",
      "metadata": {
        "id": "db29bea2-7600-495b-b57b-e2937fb0753f"
      },
      "outputs": [],
      "source": [
        "# This parses the text above into executable strings by the driver\n",
        "for line in add_comments_cql.split(\"\\n\"):\n",
        "    sc_loc = line.find(\";\")\n",
        "    if sc_loc > -1:\n",
        "        execute_statement(line[:sc_loc])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1a07cc49-7ba3-45ee-b2da-7fd297d8a86d",
      "metadata": {
        "id": "1a07cc49-7ba3-45ee-b2da-7fd297d8a86d"
      },
      "source": [
        "## Run Queries from User Questions"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "942613bc-25aa-41cc-80e9-78ca15bcee06",
      "metadata": {
        "id": "942613bc-25aa-41cc-80e9-78ca15bcee06"
      },
      "source": [
        "#### Generating & Executing CQL"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8542b137-2fd1-4105-a402-17358647f815",
      "metadata": {
        "id": "8542b137-2fd1-4105-a402-17358647f815"
      },
      "source": [
        "Now, we can ask ChatGPT to provide us with some queries that answer our questions! The prompt template we use is taken from [SQL-PaLM](https://arxiv.org/abs/2306.00739), and adapted to fit the CQL use case. In order to use it though, we need to retrieve the schema from our DB."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "7f442866-55e8-4284-83e1-705bb320250b",
      "metadata": {
        "id": "7f442866-55e8-4284-83e1-705bb320250b"
      },
      "outputs": [],
      "source": [
        "TEXT2CQL_PROMPT = \"\"\"Convert the question to CQL (Cassandra Query Language) that can retrieve an appropriate answer, or answer saying that the data model does not support answering such a question in a performant way:\n",
        "\n",
        "[Schema : values (type)]\n",
        "{schema}\n",
        "\n",
        "[Partition Keys]\n",
        "{partition_keys}\n",
        "\n",
        "[Clustering Keys]\n",
        "{clustering_keys}\n",
        "\n",
        "[Q]\n",
        "{question}\n",
        "\n",
        "[CQL]\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "def generate_schema_partition_clustering_keys(keyspace: str = ASTRA_KEYSPACE) -> (str, str):\n",
        "    \"\"\"Generates a TEXT2CQL_PROMPT compatible schema for a keyspace\"\"\"\n",
        "    # Get all table names in our keyspace\n",
        "    table_names = execute_statement(\n",
        "        f\"SELECT table_name, comment FROM system_schema.tables WHERE keyspace_name = '{keyspace}' AND table_name = 'customerprofile'\"\n",
        "    )\n",
        "    tn_str = \", \".join([\"'\" + tn.table_name + \"'\" for tn in table_names])\n",
        "\n",
        "    # Now get all the column names corresponding to those tables\n",
        "    columns = execute_statement(\n",
        "        f\"SELECT * FROM system_schema.columns WHERE table_name IN ({tn_str}) AND keyspace_name = '{keyspace}' ALLOW FILTERING\"\n",
        "    )\n",
        "\n",
        "    # Now, we construct our prompt template formatted schema, partition_keys, and clustering keys\n",
        "    # from the table and column objects returned from the DB\n",
        "    schema = \" | \".join([\n",
        "        f\"{table.table_name} '{table.comment}' : \" + \" , \".join([\n",
        "            f\"{col.column_name} ({col.type})\"\n",
        "            for col in columns\n",
        "            if col.table_name == table.table_name\n",
        "        ])\n",
        "        for table in table_names\n",
        "    ])\n",
        "    partition_keys = \" | \".join([\n",
        "        f\"{table.table_name} : \" + \" , \".join([\n",
        "            col.column_name for col in columns\n",
        "            if col.table_name == table.table_name\n",
        "            and col.kind == \"partition_key\"\n",
        "        ])\n",
        "        for table in table_names\n",
        "    ])\n",
        "    clustering_keys = \" | \".join([\n",
        "        f\"{table.table_name} : \" + \" , \".join([\n",
        "            f\"{col.column_name} ({col.clustering_order})\" for col in columns\n",
        "            if col.table_name == table.table_name\n",
        "            and col.kind == \"clustering\"\n",
        "        ])\n",
        "        for table in table_names\n",
        "    ])\n",
        "    return schema, partition_keys, clustering_keys\n",
        "\n",
        "\n",
        "def execute_query_from_question(question: str, debug_cql: bool = True, debug_prompt: bool = False, return_cql: bool = False):\n",
        "    \"\"\"Generates and executes CQL from a user question based on LLM output\"\"\"\n",
        "    # Get all of the variables necessary to fill out the prompt\n",
        "    schema, partition_keys, clustering_keys = generate_schema_partition_clustering_keys()\n",
        "    prompt = TEXT2CQL_PROMPT.format(\n",
        "        schema=schema,\n",
        "        partition_keys=partition_keys,\n",
        "        clustering_keys=clustering_keys,\n",
        "        question=question,\n",
        "    )\n",
        "\n",
        "    if debug_prompt:\n",
        "        print(f\"Prompting model with:\\n{prompt}\")\n",
        "\n",
        "    # Get generated CQL from the LLM (in this case gpt-3.5-turbo)\n",
        "    completion = client.chat.completions.create(\n",
        "        messages=[{\n",
        "            \"role\": \"user\",\n",
        "            \"content\": prompt,\n",
        "        }],\n",
        "        model=\"gpt-3.5-turbo\",\n",
        "    ).choices[0].message.content\n",
        "\n",
        "    if debug_cql:\n",
        "        print(f\"Question: {question}\\nGenerated Query: {completion}\\n\")\n",
        "\n",
        "    # Need to trim trailing ';' if present to work with cassandra-driver\n",
        "    if completion.find(\";\") > -1:\n",
        "        completion = completion[:completion.find(\";\")]\n",
        "\n",
        "    results = execute_statement(completion)\n",
        "\n",
        "    if return_cql:\n",
        "        return (results, completion)\n",
        "    else:\n",
        "        return results"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Show full prompting trace\n",
        "execute_query_from_question(\"List 3 Male customers in Thailand?\", debug_prompt=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3sVLTLM4RED1",
        "outputId": "a7093ec5-1c86-47fa-854a-679e0a8019df"
      },
      "id": "3sVLTLM4RED1",
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prompting model with:\n",
            "Convert the question to CQL (Cassandra Query Language) that can retrieve an appropriate answer, or answer saying that the data model does not support answering such a question in a performant way:\n",
            "\n",
            "[Schema : values (type)]\n",
            "customerprofile 'Customers profile with their credit scores and balance' : age (int) , balance (decimal) , card_type (text) , client_id (int) , credit_score (int) , estimated_salary (decimal) , gender (text) , has_credit_card (boolean) , location (text) , point_earned (int) , satisfaction_score (int) , surname (text)\n",
            "\n",
            "[Partition Keys]\n",
            "customerprofile : client_id\n",
            "\n",
            "[Clustering Keys]\n",
            "customerprofile : \n",
            "\n",
            "[Q]\n",
            "List 3 Male customers in Thailand?\n",
            "\n",
            "[CQL]\n",
            "\n",
            "Question: List 3 Male customers in Thailand?\n",
            "Generated Query: SELECT * FROM customerprofile WHERE gender = 'Male' AND location = 'Thailand' LIMIT 3; \n",
            "\n",
            "OR\n",
            "\n",
            "The data model does not support answering such a question in a performant way.\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Row(client_id=15741643, age=35, balance=Decimal('122917.69'), card_type='DIAMOND', credit_score=777, estimated_salary=Decimal('76169.68'), gender='Male', has_credit_card=True, location='Thailand', point_earned=624, satisfaction_score=2, surname='Chiang'),\n",
              " Row(client_id=15622993, age=28, balance=Decimal('124695.72'), card_type='DIAMOND', credit_score=709, estimated_salary=Decimal('145251.35'), gender='Male', has_credit_card=True, location='Thailand', point_earned=665, satisfaction_score=3, surname='Boyd'),\n",
              " Row(client_id=15785899, age=33, balance=Decimal('151607.56'), card_type='SILVER', credit_score=789, estimated_salary=Decimal('4389.4'), gender='Male', has_credit_card=True, location='Thailand', point_earned=513, satisfaction_score=4, surname=\"Ch'en\")]"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "id": "dd55a635-d1f5-4463-afff-b98b7bf23b56",
      "metadata": {
        "id": "dd55a635-d1f5-4463-afff-b98b7bf23b56",
        "outputId": "912e3091-f596-4e6a-dd05-d28e0150e2c1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prompting model with:\n",
            "Convert the question to CQL (Cassandra Query Language) that can retrieve an appropriate answer, or answer saying that the data model does not support answering such a question in a performant way:\n",
            "\n",
            "[Schema : values (type)]\n",
            "customerprofile 'Customers profile with their credit scores and balance' : age (int) , balance (decimal) , card_type (text) , client_id (int) , credit_score (int) , estimated_salary (decimal) , gender (text) , has_credit_card (boolean) , location (text) , point_earned (int) , satisfaction_score (int) , surname (text)\n",
            "\n",
            "[Partition Keys]\n",
            "customerprofile : client_id\n",
            "\n",
            "[Clustering Keys]\n",
            "customerprofile : \n",
            "\n",
            "[Q]\n",
            "List 3 customers in Cambodia who have credit card?\n",
            "\n",
            "[CQL]\n",
            "\n",
            "Question: List 3 customers in Cambodia who have credit card?\n",
            "Generated Query: SELECT * FROM customerprofile WHERE location = 'Cambodia' AND has_credit_card = true LIMIT 3;\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Row(client_id=15740147, age=44, balance=Decimal('0.0'), card_type='SILVER', credit_score=725, estimated_salary=Decimal('93777.61'), gender='Female', has_credit_card=True, location='Cambodia', point_earned=696, satisfaction_score=5, surname='Cremonesi'),\n",
              " Row(client_id=15625716, age=33, balance=Decimal('113913.53'), card_type='PLATINUM', credit_score=637, estimated_salary=Decimal('65316.5'), gender='Female', has_credit_card=True, location='Cambodia', point_earned=705, satisfaction_score=1, surname='Genovesi'),\n",
              " Row(client_id=15605263, age=33, balance=Decimal('140931.57'), card_type='PLATINUM', credit_score=552, estimated_salary=Decimal('10921.5'), gender='Male', has_credit_card=True, location='Cambodia', point_earned=330, satisfaction_score=5, surname='Chin')]"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ],
      "source": [
        "# Show full prompting trace\n",
        "execute_query_from_question(\"List 3 customers in Cambodia who have credit card?\", debug_prompt=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d8afb916-f30b-4bed-9e00-5e86b261d788",
      "metadata": {
        "id": "d8afb916-f30b-4bed-9e00-5e86b261d788"
      },
      "source": [
        "#### End to End Question Answering"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "09aa4a19-a284-4800-abb0-8d0e24185c38",
      "metadata": {
        "id": "09aa4a19-a284-4800-abb0-8d0e24185c38"
      },
      "source": [
        "Now, let's wrap up by showing how we can make a subsequent LLM call to answer the user's question with natural language. This completes a full \"RAG\" style pipeline!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "id": "dbb6002e-d5f1-408c-9bd3-e7ca4a329483",
      "metadata": {
        "id": "dbb6002e-d5f1-408c-9bd3-e7ca4a329483"
      },
      "outputs": [],
      "source": [
        "ANSWER_PROMPT = \"\"\"Query:\n",
        "```\n",
        "{cql}\n",
        "```\n",
        "\n",
        "Output:\n",
        "```\n",
        "{results_repr}\n",
        "```\n",
        "===\n",
        "\n",
        "Given the above results from querying the DB, answer the following user question:\n",
        "\n",
        "{question}\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "def answer_question(question: str, debug_cql: bool = False, debug_prompt: bool = False) -> str:\n",
        "    \"\"\"Conducts a full RAG pipeline where the LLM retrieves relevant information\n",
        "    and references it to answer the question in natural language.\n",
        "    \"\"\"\n",
        "    # Get necessary fields to fill out prompt\n",
        "    query_results, cql = execute_query_from_question(\n",
        "        question=question,\n",
        "        debug_cql=debug_cql,\n",
        "        debug_prompt=debug_prompt,\n",
        "        return_cql=True,\n",
        "    )\n",
        "    prompt = ANSWER_PROMPT.format(\n",
        "        question=question,\n",
        "        results_repr=str(query_results),\n",
        "        cql=cql,\n",
        "    )\n",
        "\n",
        "    if debug_prompt:\n",
        "        print(f\"Prompting model with:\\n{prompt}\")\n",
        "\n",
        "    # Return the generated answer from the LLM\n",
        "    return client.chat.completions.create(\n",
        "        messages=[{\n",
        "            \"role\": \"user\",\n",
        "            \"content\": prompt,\n",
        "        }],\n",
        "        model=\"gpt-3.5-turbo\",\n",
        "    ).choices[0].message.content\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "id": "8533ecb1-9c8e-4db1-beb4-e736d2a1b500",
      "metadata": {
        "id": "8533ecb1-9c8e-4db1-beb4-e736d2a1b500",
        "outputId": "31165a35-a296-47c4-9fd8-1b7be51e4b75",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prompting model with:\n",
            "Convert the question to CQL (Cassandra Query Language) that can retrieve an appropriate answer, or answer saying that the data model does not support answering such a question in a performant way:\n",
            "\n",
            "[Schema : values (type)]\n",
            "customerprofile 'Customers profile with their credit scores and balance' : age (int) , balance (decimal) , card_type (text) , client_id (int) , credit_score (int) , estimated_salary (decimal) , gender (text) , has_credit_card (boolean) , location (text) , point_earned (int) , satisfaction_score (int) , surname (text)\n",
            "\n",
            "[Partition Keys]\n",
            "customerprofile : client_id\n",
            "\n",
            "[Clustering Keys]\n",
            "customerprofile : \n",
            "\n",
            "[Q]\n",
            "List 3 customers in Cambodia who have credit card?\n",
            "\n",
            "[CQL]\n",
            "\n",
            "Prompting model with:\n",
            "Query:\n",
            "```\n",
            "SELECT * FROM customerprofile WHERE location = 'Cambodia' AND has_credit_card = true LIMIT 3\n",
            "```\n",
            "\n",
            "Output:\n",
            "```\n",
            "[Row(client_id=15740147, age=44, balance=Decimal('0.0'), card_type='SILVER', credit_score=725, estimated_salary=Decimal('93777.61'), gender='Female', has_credit_card=True, location='Cambodia', point_earned=696, satisfaction_score=5, surname='Cremonesi'), Row(client_id=15625716, age=33, balance=Decimal('113913.53'), card_type='PLATINUM', credit_score=637, estimated_salary=Decimal('65316.5'), gender='Female', has_credit_card=True, location='Cambodia', point_earned=705, satisfaction_score=1, surname='Genovesi'), Row(client_id=15605263, age=33, balance=Decimal('140931.57'), card_type='PLATINUM', credit_score=552, estimated_salary=Decimal('10921.5'), gender='Male', has_credit_card=True, location='Cambodia', point_earned=330, satisfaction_score=5, surname='Chin')]\n",
            "```\n",
            "===\n",
            "\n",
            "Given the above results from querying the DB, answer the following user question:\n",
            "\n",
            "List 3 customers in Cambodia who have credit card?\n",
            "\n",
            "Here are 3 customers in Cambodia who have a credit card:\n",
            "1. Client ID: 15740147, Name: Cremonesi, Age: 44, Gender: Female, Credit Card Type: Silver\n",
            "2. Client ID: 15625716, Name: Genovesi, Age: 33, Gender: Female, Credit Card Type: Platinum\n",
            "3. Client ID: 15605263, Name: Chin, Age: 33, Gender: Male, Credit Card Type: Platinum\n"
          ]
        }
      ],
      "source": [
        "# Show full prompting trace\n",
        "print(\n",
        "    answer_question(\"List 3 customers in Cambodia who have credit card?\", debug_prompt=True)\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "29edd522-6cb9-454c-a5b3-b8ee0f8a9ea8",
      "metadata": {
        "id": "29edd522-6cb9-454c-a5b3-b8ee0f8a9ea8"
      },
      "source": [
        "Awesome! Our model is answering questions based on just the data in our dummy DB, and is able to construct queries for retrieving that data in a fully automated way."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    },
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "890b2537-f585-4f31-bb20-ed71910eb586",
        "2495b975-8342-4386-b92d-5ae05b783853"
      ],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}